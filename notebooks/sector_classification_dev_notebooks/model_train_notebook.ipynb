{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install sagemaker-experiments -q\n",
    "# !pip3 install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/bobrandt/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.session import Session\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "sess = boto3.Session(region_name=\"us-west-2\")\n",
    "sm = sess.client(\"sagemaker\")\n",
    "role = os.environ.get(\"SAGEMAKER_ROLE\")\n",
    "\n",
    "region = Session().boto_session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Experiment in SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sector-classification-experiments-v0\n"
     ]
    }
   ],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "\n",
    "experiment_name = f\"sector-classification-experiments-v0\"\n",
    "sector_class_experiment = Experiment.create(\n",
    "    experiment_name=experiment_name,\n",
    "    description=\"Sector / Subsector Classification experiments - v0\",\n",
    "    sagemaker_boto_client=sm,\n",
    ")\n",
    "\n",
    "experiment_name = sector_class_experiment.experiment_name\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S3 URI's to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "s3_data_root_folder = f\"s3://team-orange-datasets\"\n",
    "train_input_path = os.path.join(s3_data_root_folder, \"subsector-classification\", \"train\")\n",
    "test_input_path = os.path.join(s3_data_root_folder, \"subsector-classification\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train HuggingFace Model via SageMaker Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2024-06-11-19-08-39-219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-11 19:08:41 Starting - Starting the training job...\n",
      "2024-06-11 19:08:57 Starting - Preparing the instances for training...\n",
      "2024-06-11 19:09:28 Downloading - Downloading input data...\n",
      "2024-06-11 19:09:53 Downloading - Downloading the training image..................\n",
      "2024-06-11 19:13:09 Training - Training image download completed. Training in progress..bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-06-11 19:13:21,224 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-06-11 19:13:21,245 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-06-11 19:13:21,255 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-06-11 19:13:21,260 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-06-11 19:13:22,411 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.9 -m pip install -r requirements.txt\n",
      "Collecting datasets==2.11.0 (from -r requirements.txt (line 1))\n",
      "Obtaining dependency information for datasets==2.11.0 from https://files.pythonhosted.org/packages/48/b7/6190994c06fb2cee1ff25c4326312a5c38c20e721424c332195f65af5190/datasets-2.11.0-py3-none-any.whl.metadata\n",
      "Downloading datasets-2.11.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (4.26.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.13.1+cu117)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: s3fs==0.4.2 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (0.4.2)\n",
      "Requirement already satisfied: sagemaker<3,>=2.48.0 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (2.132.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (14.0.2)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (0.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (0.22.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from datasets==2.11.0->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /opt/conda/lib/python3.9/site-packages (from s3fs==0.4.2->-r requirements.txt (line 6)) (1.31.10)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers[torch]->-r requirements.txt (line 2)) (3.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers[torch]->-r requirements.txt (line 2)) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers[torch]->-r requirements.txt (line 2)) (0.13.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch->-r requirements.txt (line 3)) (4.7.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (22.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.28 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (1.28.10)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (3.20.2)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (0.1.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (4.13.0)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (0.7.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 8)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 8)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 8)) (2023.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (0.6.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.9/site-packages (from botocore>=1.12.91->s3fs==0.4.2->-r requirements.txt (line 6)) (1.26.14)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets==2.11.0->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets==2.11.0->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets==2.11.0->-r requirements.txt (line 1)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets==2.11.0->-r requirements.txt (line 1)) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets==2.11.0->-r requirements.txt (line 1)) (4.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (3.16.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.11.0->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.11.0->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.11.0->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (1.7.6.7)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (0.3.3)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.9/site-packages (from schema->sagemaker<3,>=2.48.0->-r requirements.txt (line 7)) (21.6.0)\n",
      "Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 468.7/468.7 kB 13.0 MB/s eta 0:00:00\n",
      "Installing collected packages: datasets\n",
      "Attempting uninstall: datasets\n",
      "Found existing installation: datasets 2.16.1\n",
      "Uninstalling datasets-2.16.1:\n",
      "Successfully uninstalled datasets-2.16.1\n",
      "Successfully installed datasets-2.11.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2024-06-11 19:13:26,103 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-06-11 19:13:26,103 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-06-11 19:13:26,153 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-06-11 19:13:26,199 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-06-11 19:13:26,241 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-06-11 19:13:26,259 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 2,\n",
      "        \"learning_rate\": 5e-05,\n",
      "        \"model_name\": \"bert-base-uncased\",\n",
      "        \"train_batch_size\": 8,\n",
      "        \"weight_decay\": 0\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2024-06-11-19-08-39-219\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-597915789054/huggingface-pytorch-training-2024-06-11-19-08-39-219/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"epochs\":2,\"learning_rate\":5e-05,\"model_name\":\"bert-base-uncased\",\"train_batch_size\":8,\"weight_decay\":0}\n",
      "SM_USER_ENTRY_POINT=train.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-west-2-597915789054/huggingface-pytorch-training-2024-06-11-19-08-39-219/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":2,\"learning_rate\":5e-05,\"model_name\":\"bert-base-uncased\",\"train_batch_size\":8,\"weight_decay\":0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2024-06-11-19-08-39-219\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-597915789054/huggingface-pytorch-training-2024-06-11-19-08-39-219/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\n",
      "SM_USER_ARGS=[\"--epochs\",\"2\",\"--learning_rate\",\"5e-05\",\"--model_name\",\"bert-base-uncased\",\"--train_batch_size\",\"8\",\"--weight_decay\",\"0\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_HP_EPOCHS=2\n",
      "SM_HP_LEARNING_RATE=5e-05\n",
      "SM_HP_MODEL_NAME=bert-base-uncased\n",
      "SM_HP_TRAIN_BATCH_SIZE=8\n",
      "SM_HP_WEIGHT_DECAY=0\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.9 train.py --epochs 2 --learning_rate 5e-05 --model_name bert-base-uncased --train_batch_size 8 --weight_decay 0\n",
      "2024-06-11 19:13:26,291 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "Map:   0%|          | 0/3206 [00:00<?, ? examples/s]\n",
      "Map:  31%|███       | 1000/3206 [00:00<00:00, 3070.91 examples/s]\n",
      "Map:  62%|██████▏   | 2000/3206 [00:00<00:00, 3136.65 examples/s]\n",
      "Map:  94%|█████████▎| 3000/3206 [00:00<00:00, 3143.91 examples/s]\n",
      "Map:   0%|          | 0/357 [00:00<?, ? examples/s]\n",
      "Map: 100%|██████████| 357/357 [00:00<00:00, 3226.37 examples/s]\n",
      "INFO:__main__:Loaded train_dataset length is: 3206\n",
      "INFO:__main__:Loaded test_dataset length is: 357\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:sagemaker.experiments.run:The run (bert-base-uncased-epoch-2-lr-5e-05-wd-0-1718132917) under experiment (sector-classification-experiments-v0) already exists. Loading it. Note: sagemaker.experiments.load_run is recommended to use when the desired run already exists.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "Num examples = 3206\n",
      "***** Running training *****\n",
      "  Num examples = 3206\n",
      "  Num Epochs = 2\n",
      "Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 802\n",
      "Total optimization steps = 802\n",
      "Number of trainable parameters = 109516845\n",
      "Number of trainable parameters = 109516845\n",
      "0%|          | 0/802 [00:00<?, ?it/s]\n",
      "[2024-06-11 19:13:36.501 algo-1:50 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2024-06-11 19:13:36.559 algo-1:50 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[2024-06-11 19:13:36.560 algo-1:50 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[2024-06-11 19:13:36.560 algo-1:50 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2024-06-11 19:13:36.561 algo-1:50 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[2024-06-11 19:13:36.561 algo-1:50 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "0%|          | 1/802 [00:01<20:05,  1.51s/it]\n",
      "0%|          | 2/802 [00:02<13:19,  1.00it/s]\n",
      "0%|          | 3/802 [00:02<11:06,  1.20it/s]\n",
      "0%|          | 4/802 [00:03<10:06,  1.32it/s]\n",
      "1%|          | 5/802 [00:04<09:32,  1.39it/s]\n",
      "1%|          | 6/802 [00:04<09:12,  1.44it/s]\n",
      "1%|          | 7/802 [00:05<08:58,  1.48it/s]\n",
      "1%|          | 8/802 [00:06<08:48,  1.50it/s]\n",
      "1%|          | 9/802 [00:06<08:42,  1.52it/s]\n",
      "1%|          | 10/802 [00:07<08:39,  1.52it/s]\n",
      "1%|▏         | 11/802 [00:07<08:36,  1.53it/s]\n",
      "1%|▏         | 12/802 [00:08<08:35,  1.53it/s]\n",
      "2%|▏         | 13/802 [00:09<08:33,  1.54it/s]\n",
      "2%|▏         | 14/802 [00:09<08:32,  1.54it/s]\n",
      "2%|▏         | 15/802 [00:10<08:31,  1.54it/s]\n",
      "2%|▏         | 16/802 [00:11<08:30,  1.54it/s]\n",
      "2%|▏         | 17/802 [00:11<08:27,  1.55it/s]\n",
      "2%|▏         | 18/802 [00:12<08:27,  1.54it/s]\n",
      "2%|▏         | 19/802 [00:13<08:27,  1.54it/s]\n",
      "2%|▏         | 20/802 [00:13<08:26,  1.54it/s]\n",
      "3%|▎         | 21/802 [00:14<08:26,  1.54it/s]\n",
      "3%|▎         | 22/802 [00:15<08:26,  1.54it/s]\n",
      "3%|▎         | 23/802 [00:15<08:25,  1.54it/s]\n",
      "3%|▎         | 24/802 [00:16<08:24,  1.54it/s]\n",
      "3%|▎         | 25/802 [00:17<08:23,  1.54it/s]\n",
      "3%|▎         | 26/802 [00:17<08:23,  1.54it/s]\n",
      "3%|▎         | 27/802 [00:18<08:23,  1.54it/s]\n",
      "3%|▎         | 28/802 [00:18<08:23,  1.54it/s]\n",
      "4%|▎         | 29/802 [00:19<08:23,  1.54it/s]\n",
      "4%|▎         | 30/802 [00:20<08:22,  1.54it/s]\n",
      "4%|▍         | 31/802 [00:20<08:21,  1.54it/s]\n",
      "4%|▍         | 32/802 [00:21<08:21,  1.54it/s]\n",
      "4%|▍         | 33/802 [00:22<08:19,  1.54it/s]\n",
      "4%|▍         | 34/802 [00:22<08:20,  1.53it/s]\n",
      "4%|▍         | 35/802 [00:23<08:19,  1.53it/s]\n",
      "4%|▍         | 36/802 [00:24<08:20,  1.53it/s]\n",
      "5%|▍         | 37/802 [00:24<08:20,  1.53it/s]\n",
      "5%|▍         | 38/802 [00:25<08:19,  1.53it/s]\n",
      "5%|▍         | 39/802 [00:26<08:18,  1.53it/s]\n",
      "5%|▍         | 40/802 [00:26<08:19,  1.52it/s]\n",
      "5%|▌         | 41/802 [00:27<08:18,  1.53it/s]\n",
      "5%|▌         | 42/802 [00:28<08:17,  1.53it/s]\n",
      "5%|▌         | 43/802 [00:28<08:17,  1.53it/s]\n",
      "5%|▌         | 44/802 [00:29<08:16,  1.53it/s]\n",
      "6%|▌         | 45/802 [00:30<08:16,  1.52it/s]\n",
      "6%|▌         | 46/802 [00:30<08:16,  1.52it/s]\n",
      "6%|▌         | 47/802 [00:31<08:14,  1.53it/s]\n",
      "6%|▌         | 48/802 [00:32<08:13,  1.53it/s]\n",
      "6%|▌         | 49/802 [00:32<08:11,  1.53it/s]\n",
      "6%|▌         | 50/802 [00:33<08:12,  1.53it/s]\n",
      "6%|▋         | 51/802 [00:34<08:11,  1.53it/s]\n",
      "6%|▋         | 52/802 [00:34<08:10,  1.53it/s]\n",
      "7%|▋         | 53/802 [00:35<08:10,  1.53it/s]\n",
      "7%|▋         | 54/802 [00:35<08:09,  1.53it/s]\n",
      "7%|▋         | 55/802 [00:36<08:08,  1.53it/s]\n",
      "7%|▋         | 56/802 [00:37<08:08,  1.53it/s]\n",
      "7%|▋         | 57/802 [00:37<08:08,  1.53it/s]\n",
      "7%|▋         | 58/802 [00:38<08:07,  1.53it/s]\n",
      "7%|▋         | 59/802 [00:39<08:07,  1.53it/s]\n",
      "7%|▋         | 60/802 [00:39<08:07,  1.52it/s]\n",
      "8%|▊         | 61/802 [00:40<08:07,  1.52it/s]\n",
      "8%|▊         | 62/802 [00:41<08:06,  1.52it/s]\n",
      "8%|▊         | 63/802 [00:41<08:06,  1.52it/s]\n",
      "8%|▊         | 64/802 [00:42<08:05,  1.52it/s]\n",
      "8%|▊         | 65/802 [00:43<08:05,  1.52it/s]\n",
      "8%|▊         | 66/802 [00:43<08:02,  1.52it/s]\n",
      "8%|▊         | 67/802 [00:44<08:02,  1.52it/s]\n",
      "8%|▊         | 68/802 [00:45<08:02,  1.52it/s]\n",
      "9%|▊         | 69/802 [00:45<08:01,  1.52it/s]\n",
      "9%|▊         | 70/802 [00:46<08:01,  1.52it/s]\n",
      "9%|▉         | 71/802 [00:47<08:00,  1.52it/s]\n",
      "9%|▉         | 72/802 [00:47<08:00,  1.52it/s]\n",
      "9%|▉         | 73/802 [00:48<07:59,  1.52it/s]\n",
      "9%|▉         | 74/802 [00:49<08:00,  1.52it/s]\n",
      "9%|▉         | 75/802 [00:49<07:58,  1.52it/s]\n",
      "9%|▉         | 76/802 [00:50<07:59,  1.51it/s]\n",
      "10%|▉         | 77/802 [00:51<07:58,  1.52it/s]\n",
      "10%|▉         | 78/802 [00:51<07:58,  1.51it/s]\n",
      "10%|▉         | 79/802 [00:52<07:58,  1.51it/s]\n",
      "10%|▉         | 80/802 [00:53<07:56,  1.51it/s]\n",
      "10%|█         | 81/802 [00:53<07:56,  1.51it/s]\n",
      "10%|█         | 82/802 [00:54<07:55,  1.51it/s]\n",
      "10%|█         | 83/802 [00:55<07:54,  1.51it/s]\n",
      "10%|█         | 84/802 [00:55<07:53,  1.52it/s]\n",
      "11%|█         | 85/802 [00:56<07:53,  1.51it/s]\n",
      "11%|█         | 86/802 [00:57<07:54,  1.51it/s]\n",
      "11%|█         | 87/802 [00:57<07:52,  1.51it/s]\n",
      "11%|█         | 88/802 [00:58<07:52,  1.51it/s]\n",
      "11%|█         | 89/802 [00:59<07:52,  1.51it/s]\n",
      "11%|█         | 90/802 [00:59<07:50,  1.51it/s]\n",
      "11%|█▏        | 91/802 [01:00<07:50,  1.51it/s]\n",
      "11%|█▏        | 92/802 [01:01<07:51,  1.51it/s]\n",
      "12%|█▏        | 93/802 [01:01<07:49,  1.51it/s]\n",
      "12%|█▏        | 94/802 [01:02<07:49,  1.51it/s]\n",
      "12%|█▏        | 95/802 [01:03<07:48,  1.51it/s]\n",
      "12%|█▏        | 96/802 [01:03<07:46,  1.51it/s]\n",
      "12%|█▏        | 97/802 [01:04<07:46,  1.51it/s]\n",
      "12%|█▏        | 98/802 [01:05<07:46,  1.51it/s]\n",
      "12%|█▏        | 99/802 [01:05<07:46,  1.51it/s]\n",
      "12%|█▏        | 100/802 [01:06<07:44,  1.51it/s]\n",
      "13%|█▎        | 101/802 [01:06<07:44,  1.51it/s]\n",
      "13%|█▎        | 102/802 [01:07<07:44,  1.51it/s]\n",
      "13%|█▎        | 103/802 [01:08<07:42,  1.51it/s]\n",
      "13%|█▎        | 104/802 [01:08<07:42,  1.51it/s]\n",
      "13%|█▎        | 105/802 [01:09<07:41,  1.51it/s]\n",
      "13%|█▎        | 106/802 [01:10<07:39,  1.51it/s]\n",
      "13%|█▎        | 107/802 [01:10<07:39,  1.51it/s]\n",
      "13%|█▎        | 108/802 [01:11<07:39,  1.51it/s]\n",
      "14%|█▎        | 109/802 [01:12<07:38,  1.51it/s]\n",
      "14%|█▎        | 110/802 [01:12<07:38,  1.51it/s]\n",
      "14%|█▍        | 111/802 [01:13<07:38,  1.51it/s]\n",
      "14%|█▍        | 112/802 [01:14<07:40,  1.50it/s]\n",
      "14%|█▍        | 113/802 [01:14<07:38,  1.50it/s]\n",
      "14%|█▍        | 114/802 [01:15<07:38,  1.50it/s]\n",
      "14%|█▍        | 115/802 [01:16<07:37,  1.50it/s]\n",
      "14%|█▍        | 116/802 [01:16<07:35,  1.51it/s]\n",
      "15%|█▍        | 117/802 [01:17<07:33,  1.51it/s]\n",
      "15%|█▍        | 118/802 [01:18<07:32,  1.51it/s]\n",
      "15%|█▍        | 119/802 [01:18<07:33,  1.51it/s]\n",
      "15%|█▍        | 120/802 [01:19<07:32,  1.51it/s]\n",
      "15%|█▌        | 121/802 [01:20<07:32,  1.51it/s]\n",
      "15%|█▌        | 122/802 [01:20<07:31,  1.50it/s]\n",
      "15%|█▌        | 123/802 [01:21<07:30,  1.51it/s]\n",
      "15%|█▌        | 124/802 [01:22<07:30,  1.51it/s]\n",
      "16%|█▌        | 125/802 [01:22<07:28,  1.51it/s]\n",
      "16%|█▌        | 126/802 [01:23<07:28,  1.51it/s]\n",
      "16%|█▌        | 127/802 [01:24<07:27,  1.51it/s]\n",
      "16%|█▌        | 128/802 [01:24<07:29,  1.50it/s]\n",
      "16%|█▌        | 129/802 [01:25<07:27,  1.50it/s]\n",
      "16%|█▌        | 130/802 [01:26<07:27,  1.50it/s]\n",
      "16%|█▋        | 131/802 [01:26<07:26,  1.50it/s]\n",
      "16%|█▋        | 132/802 [01:27<07:26,  1.50it/s]\n",
      "17%|█▋        | 133/802 [01:28<07:25,  1.50it/s]\n",
      "17%|█▋        | 134/802 [01:28<07:24,  1.50it/s]\n",
      "17%|█▋        | 135/802 [01:29<07:22,  1.51it/s]\n",
      "17%|█▋        | 136/802 [01:30<07:22,  1.50it/s]\n",
      "17%|█▋        | 137/802 [01:30<07:21,  1.51it/s]\n",
      "17%|█▋        | 138/802 [01:31<07:21,  1.51it/s]\n",
      "17%|█▋        | 139/802 [01:32<07:19,  1.51it/s]\n",
      "17%|█▋        | 140/802 [01:32<07:18,  1.51it/s]\n",
      "18%|█▊        | 141/802 [01:33<07:18,  1.51it/s]\n",
      "18%|█▊        | 142/802 [01:34<07:18,  1.50it/s]\n",
      "18%|█▊        | 143/802 [01:34<07:18,  1.50it/s]\n",
      "18%|█▊        | 144/802 [01:35<07:18,  1.50it/s]\n",
      "18%|█▊        | 145/802 [01:36<07:15,  1.51it/s]\n",
      "18%|█▊        | 146/802 [01:36<07:16,  1.50it/s]\n",
      "18%|█▊        | 147/802 [01:37<07:15,  1.51it/s]\n",
      "18%|█▊        | 148/802 [01:38<07:15,  1.50it/s]\n",
      "19%|█▊        | 149/802 [01:38<07:13,  1.50it/s]\n",
      "19%|█▊        | 150/802 [01:39<07:13,  1.50it/s]\n",
      "19%|█▉        | 151/802 [01:40<07:12,  1.51it/s]\n",
      "19%|█▉        | 152/802 [01:40<07:12,  1.50it/s]\n",
      "19%|█▉        | 153/802 [01:41<07:11,  1.50it/s]\n",
      "19%|█▉        | 154/802 [01:42<07:10,  1.50it/s]\n",
      "19%|█▉        | 155/802 [01:42<07:10,  1.50it/s]\n",
      "19%|█▉        | 156/802 [01:43<07:09,  1.50it/s]\n",
      "20%|█▉        | 157/802 [01:44<07:09,  1.50it/s]\n",
      "20%|█▉        | 158/802 [01:44<07:09,  1.50it/s]\n",
      "20%|█▉        | 159/802 [01:45<07:08,  1.50it/s]\n",
      "20%|█▉        | 160/802 [01:46<07:08,  1.50it/s]\n",
      "20%|██        | 161/802 [01:46<07:07,  1.50it/s]\n",
      "20%|██        | 162/802 [01:47<07:06,  1.50it/s]\n",
      "20%|██        | 163/802 [01:48<07:04,  1.50it/s]\n",
      "20%|██        | 164/802 [01:48<07:04,  1.50it/s]\n",
      "21%|██        | 165/802 [01:49<07:04,  1.50it/s]\n",
      "21%|██        | 166/802 [01:50<07:02,  1.50it/s]\n",
      "21%|██        | 167/802 [01:50<07:03,  1.50it/s]\n",
      "21%|██        | 168/802 [01:51<07:02,  1.50it/s]\n",
      "21%|██        | 169/802 [01:52<07:02,  1.50it/s]\n",
      "21%|██        | 170/802 [01:52<07:02,  1.50it/s]\n",
      "21%|██▏       | 171/802 [01:53<07:01,  1.50it/s]\n",
      "21%|██▏       | 172/802 [01:54<06:59,  1.50it/s]\n",
      "22%|██▏       | 173/802 [01:54<06:58,  1.50it/s]\n",
      "22%|██▏       | 174/802 [01:55<06:58,  1.50it/s]\n",
      "22%|██▏       | 175/802 [01:56<06:57,  1.50it/s]\n",
      "22%|██▏       | 176/802 [01:56<06:57,  1.50it/s]\n",
      "22%|██▏       | 177/802 [01:57<06:57,  1.50it/s]\n",
      "22%|██▏       | 178/802 [01:58<06:56,  1.50it/s]\n",
      "22%|██▏       | 179/802 [01:58<06:55,  1.50it/s]\n",
      "22%|██▏       | 180/802 [01:59<06:54,  1.50it/s]\n",
      "23%|██▎       | 181/802 [02:00<06:53,  1.50it/s]\n",
      "23%|██▎       | 182/802 [02:00<06:53,  1.50it/s]\n",
      "23%|██▎       | 183/802 [02:01<06:52,  1.50it/s]\n",
      "23%|██▎       | 184/802 [02:02<06:52,  1.50it/s]\n",
      "23%|██▎       | 185/802 [02:02<06:51,  1.50it/s]\n",
      "23%|██▎       | 186/802 [02:03<06:50,  1.50it/s]\n",
      "23%|██▎       | 187/802 [02:04<06:50,  1.50it/s]\n",
      "23%|██▎       | 188/802 [02:04<06:49,  1.50it/s]\n",
      "24%|██▎       | 189/802 [02:05<06:47,  1.50it/s]\n",
      "24%|██▎       | 190/802 [02:06<06:46,  1.50it/s]\n",
      "24%|██▍       | 191/802 [02:06<06:46,  1.50it/s]\n",
      "24%|██▍       | 192/802 [02:07<06:46,  1.50it/s]\n",
      "24%|██▍       | 193/802 [02:08<06:46,  1.50it/s]\n",
      "24%|██▍       | 194/802 [02:08<06:46,  1.50it/s]\n",
      "24%|██▍       | 195/802 [02:09<06:45,  1.50it/s]\n",
      "24%|██▍       | 196/802 [02:10<06:44,  1.50it/s]\n",
      "25%|██▍       | 197/802 [02:10<06:44,  1.50it/s]\n",
      "25%|██▍       | 198/802 [02:11<06:43,  1.50it/s]\n",
      "25%|██▍       | 199/802 [02:12<06:43,  1.49it/s]\n",
      "25%|██▍       | 200/802 [02:12<06:42,  1.50it/s]\n",
      "25%|██▌       | 201/802 [02:13<06:42,  1.49it/s]\n",
      "25%|██▌       | 202/802 [02:14<06:40,  1.50it/s]\n",
      "25%|██▌       | 203/802 [02:14<06:40,  1.50it/s]\n",
      "25%|██▌       | 204/802 [02:15<06:39,  1.50it/s]\n",
      "26%|██▌       | 205/802 [02:16<06:38,  1.50it/s]\n",
      "26%|██▌       | 206/802 [02:16<06:38,  1.50it/s]\n",
      "26%|██▌       | 207/802 [02:17<06:37,  1.50it/s]\n",
      "26%|██▌       | 208/802 [02:18<06:36,  1.50it/s]\n",
      "26%|██▌       | 209/802 [02:18<06:35,  1.50it/s]\n",
      "26%|██▌       | 210/802 [02:19<06:33,  1.50it/s]\n",
      "26%|██▋       | 211/802 [02:20<06:33,  1.50it/s]\n",
      "26%|██▋       | 212/802 [02:20<06:32,  1.50it/s]\n",
      "27%|██▋       | 213/802 [02:21<06:32,  1.50it/s]\n",
      "27%|██▋       | 214/802 [02:22<06:31,  1.50it/s]\n",
      "27%|██▋       | 215/802 [02:22<06:30,  1.50it/s]\n",
      "27%|██▋       | 216/802 [02:23<06:30,  1.50it/s]\n",
      "27%|██▋       | 217/802 [02:24<06:30,  1.50it/s]\n",
      "27%|██▋       | 218/802 [02:24<06:30,  1.50it/s]\n",
      "27%|██▋       | 219/802 [02:25<06:29,  1.50it/s]\n",
      "27%|██▋       | 220/802 [02:26<06:28,  1.50it/s]\n",
      "28%|██▊       | 221/802 [02:26<06:27,  1.50it/s]\n",
      "28%|██▊       | 222/802 [02:27<06:27,  1.50it/s]\n",
      "28%|██▊       | 223/802 [02:28<06:27,  1.50it/s]\n",
      "28%|██▊       | 224/802 [02:28<06:26,  1.50it/s]\n",
      "28%|██▊       | 225/802 [02:29<06:25,  1.50it/s]\n",
      "28%|██▊       | 226/802 [02:30<06:24,  1.50it/s]\n",
      "28%|██▊       | 227/802 [02:30<06:24,  1.50it/s]\n",
      "28%|██▊       | 228/802 [02:31<06:23,  1.50it/s]\n",
      "29%|██▊       | 229/802 [02:32<06:22,  1.50it/s]\n",
      "29%|██▊       | 230/802 [02:32<06:22,  1.50it/s]\n",
      "29%|██▉       | 231/802 [02:33<06:21,  1.50it/s]\n",
      "29%|██▉       | 232/802 [02:34<06:20,  1.50it/s]\n",
      "29%|██▉       | 233/802 [02:34<06:20,  1.50it/s]\n",
      "29%|██▉       | 234/802 [02:35<06:19,  1.50it/s]\n",
      "29%|██▉       | 235/802 [02:36<06:18,  1.50it/s]\n",
      "29%|██▉       | 236/802 [02:36<06:17,  1.50it/s]\n",
      "30%|██▉       | 237/802 [02:37<06:17,  1.50it/s]\n",
      "30%|██▉       | 238/802 [02:38<06:17,  1.50it/s]\n",
      "30%|██▉       | 239/802 [02:38<06:16,  1.50it/s]\n",
      "30%|██▉       | 240/802 [02:39<06:15,  1.50it/s]\n",
      "30%|███       | 241/802 [02:40<06:14,  1.50it/s]\n",
      "30%|███       | 242/802 [02:40<06:14,  1.50it/s]\n",
      "30%|███       | 243/802 [02:41<06:13,  1.50it/s]\n",
      "30%|███       | 244/802 [02:42<06:12,  1.50it/s]\n",
      "31%|███       | 245/802 [02:42<06:11,  1.50it/s]\n",
      "31%|███       | 246/802 [02:43<06:11,  1.50it/s]\n",
      "31%|███       | 247/802 [02:44<06:10,  1.50it/s]\n",
      "31%|███       | 248/802 [02:44<06:10,  1.50it/s]\n",
      "31%|███       | 249/802 [02:45<06:09,  1.50it/s]\n",
      "31%|███       | 250/802 [02:46<06:08,  1.50it/s]\n",
      "31%|███▏      | 251/802 [02:46<06:08,  1.50it/s]\n",
      "31%|███▏      | 252/802 [02:47<06:07,  1.50it/s]\n",
      "32%|███▏      | 253/802 [02:48<06:07,  1.49it/s]\n",
      "32%|███▏      | 254/802 [02:48<06:06,  1.50it/s]\n",
      "32%|███▏      | 255/802 [02:49<06:05,  1.50it/s]\n",
      "32%|███▏      | 256/802 [02:50<06:04,  1.50it/s]\n",
      "32%|███▏      | 257/802 [02:50<06:04,  1.50it/s]\n",
      "32%|███▏      | 258/802 [02:51<06:03,  1.50it/s]\n",
      "32%|███▏      | 259/802 [02:52<06:02,  1.50it/s]\n",
      "32%|███▏      | 260/802 [02:52<06:02,  1.50it/s]\n",
      "33%|███▎      | 261/802 [02:53<06:01,  1.50it/s]\n",
      "33%|███▎      | 262/802 [02:54<06:01,  1.50it/s]\n",
      "33%|███▎      | 263/802 [02:54<05:59,  1.50it/s]\n",
      "33%|███▎      | 264/802 [02:55<05:59,  1.50it/s]\n",
      "33%|███▎      | 265/802 [02:56<05:58,  1.50it/s]\n",
      "33%|███▎      | 266/802 [02:56<05:58,  1.50it/s]\n",
      "33%|███▎      | 267/802 [02:57<05:57,  1.50it/s]\n",
      "33%|███▎      | 268/802 [02:58<05:56,  1.50it/s]\n",
      "34%|███▎      | 269/802 [02:58<05:56,  1.50it/s]\n",
      "34%|███▎      | 270/802 [02:59<05:55,  1.50it/s]\n",
      "34%|███▍      | 271/802 [03:00<05:55,  1.50it/s]\n",
      "34%|███▍      | 272/802 [03:00<05:54,  1.50it/s]\n",
      "34%|███▍      | 273/802 [03:01<05:53,  1.49it/s]\n",
      "34%|███▍      | 274/802 [03:02<05:52,  1.50it/s]\n",
      "34%|███▍      | 275/802 [03:02<05:52,  1.50it/s]\n",
      "34%|███▍      | 276/802 [03:03<05:51,  1.49it/s]\n",
      "35%|███▍      | 277/802 [03:04<05:51,  1.50it/s]\n",
      "35%|███▍      | 278/802 [03:04<05:50,  1.50it/s]\n",
      "35%|███▍      | 279/802 [03:05<05:48,  1.50it/s]\n",
      "35%|███▍      | 280/802 [03:06<05:48,  1.50it/s]\n",
      "35%|███▌      | 281/802 [03:06<05:46,  1.50it/s]\n",
      "35%|███▌      | 282/802 [03:07<05:46,  1.50it/s]\n",
      "35%|███▌      | 283/802 [03:08<05:46,  1.50it/s]\n",
      "35%|███▌      | 284/802 [03:08<05:45,  1.50it/s]\n",
      "36%|███▌      | 285/802 [03:09<05:45,  1.50it/s]\n",
      "36%|███▌      | 286/802 [03:10<05:44,  1.50it/s]\n",
      "36%|███▌      | 287/802 [03:10<05:43,  1.50it/s]\n",
      "36%|███▌      | 288/802 [03:11<05:43,  1.49it/s]\n",
      "36%|███▌      | 289/802 [03:12<05:43,  1.50it/s]\n",
      "36%|███▌      | 290/802 [03:12<05:42,  1.50it/s]\n",
      "36%|███▋      | 291/802 [03:13<05:41,  1.50it/s]\n",
      "36%|███▋      | 292/802 [03:14<05:40,  1.50it/s]\n",
      "37%|███▋      | 293/802 [03:14<05:39,  1.50it/s]\n",
      "37%|███▋      | 294/802 [03:15<05:37,  1.50it/s]\n",
      "37%|███▋      | 295/802 [03:16<05:37,  1.50it/s]\n",
      "37%|███▋      | 296/802 [03:16<05:37,  1.50it/s]\n",
      "37%|███▋      | 297/802 [03:17<05:36,  1.50it/s]\n",
      "37%|███▋      | 298/802 [03:18<05:36,  1.50it/s]\n",
      "37%|███▋      | 299/802 [03:18<05:35,  1.50it/s]\n",
      "37%|███▋      | 300/802 [03:19<05:35,  1.50it/s]\n",
      "38%|███▊      | 301/802 [03:20<05:34,  1.50it/s]\n",
      "38%|███▊      | 302/802 [03:20<05:33,  1.50it/s]\n",
      "38%|███▊      | 303/802 [03:21<05:33,  1.50it/s]\n",
      "38%|███▊      | 304/802 [03:22<05:32,  1.50it/s]\n",
      "38%|███▊      | 305/802 [03:22<05:31,  1.50it/s]\n",
      "38%|███▊      | 306/802 [03:23<05:31,  1.50it/s]\n",
      "38%|███▊      | 307/802 [03:24<05:30,  1.50it/s]\n",
      "38%|███▊      | 308/802 [03:24<05:30,  1.49it/s]\n",
      "39%|███▊      | 309/802 [03:25<05:30,  1.49it/s]\n",
      "39%|███▊      | 310/802 [03:26<05:29,  1.49it/s]\n",
      "39%|███▉      | 311/802 [03:27<05:27,  1.50it/s]\n",
      "39%|███▉      | 312/802 [03:27<05:27,  1.50it/s]\n",
      "39%|███▉      | 313/802 [03:28<05:26,  1.50it/s]\n",
      "39%|███▉      | 314/802 [03:29<05:26,  1.50it/s]\n",
      "39%|███▉      | 315/802 [03:29<05:25,  1.50it/s]\n",
      "39%|███▉      | 316/802 [03:30<05:24,  1.50it/s]\n",
      "40%|███▉      | 317/802 [03:31<05:23,  1.50it/s]\n",
      "40%|███▉      | 318/802 [03:31<05:23,  1.50it/s]\n",
      "40%|███▉      | 319/802 [03:32<05:22,  1.50it/s]\n",
      "40%|███▉      | 320/802 [03:33<05:22,  1.50it/s]\n",
      "40%|████      | 321/802 [03:33<05:21,  1.50it/s]\n",
      "40%|████      | 322/802 [03:34<05:20,  1.50it/s]\n",
      "40%|████      | 323/802 [03:35<05:20,  1.50it/s]\n",
      "40%|████      | 324/802 [03:35<05:19,  1.50it/s]\n",
      "41%|████      | 325/802 [03:36<05:19,  1.49it/s]\n",
      "41%|████      | 326/802 [03:37<05:18,  1.50it/s]\n",
      "41%|████      | 327/802 [03:37<05:17,  1.50it/s]\n",
      "41%|████      | 328/802 [03:38<05:16,  1.50it/s]\n",
      "41%|████      | 329/802 [03:39<05:16,  1.50it/s]\n",
      "41%|████      | 330/802 [03:39<05:15,  1.50it/s]\n",
      "41%|████▏     | 331/802 [03:40<05:14,  1.50it/s]\n",
      "41%|████▏     | 332/802 [03:41<05:14,  1.49it/s]\n",
      "42%|████▏     | 333/802 [03:41<05:13,  1.50it/s]\n",
      "42%|████▏     | 334/802 [03:42<05:13,  1.49it/s]\n",
      "42%|████▏     | 335/802 [03:43<05:12,  1.50it/s]\n",
      "42%|████▏     | 336/802 [03:43<05:11,  1.50it/s]\n",
      "42%|████▏     | 337/802 [03:44<05:10,  1.50it/s]\n",
      "42%|████▏     | 338/802 [03:45<05:10,  1.50it/s]\n",
      "42%|████▏     | 339/802 [03:45<05:09,  1.50it/s]\n",
      "42%|████▏     | 340/802 [03:46<05:08,  1.50it/s]\n",
      "43%|████▎     | 341/802 [03:47<05:07,  1.50it/s]\n",
      "43%|████▎     | 342/802 [03:47<05:07,  1.50it/s]\n",
      "43%|████▎     | 343/802 [03:48<05:06,  1.50it/s]\n",
      "43%|████▎     | 344/802 [03:49<05:06,  1.50it/s]\n",
      "43%|████▎     | 345/802 [03:49<05:05,  1.49it/s]\n",
      "43%|████▎     | 346/802 [03:50<05:04,  1.50it/s]\n",
      "43%|████▎     | 347/802 [03:51<05:04,  1.50it/s]\n",
      "43%|████▎     | 348/802 [03:51<05:03,  1.50it/s]\n",
      "44%|████▎     | 349/802 [03:52<05:02,  1.50it/s]\n",
      "44%|████▎     | 350/802 [03:53<05:02,  1.50it/s]\n",
      "44%|████▍     | 351/802 [03:53<05:01,  1.50it/s]\n",
      "44%|████▍     | 352/802 [03:54<05:00,  1.50it/s]\n",
      "44%|████▍     | 353/802 [03:55<04:59,  1.50it/s]\n",
      "44%|████▍     | 354/802 [03:55<04:59,  1.50it/s]\n",
      "44%|████▍     | 355/802 [03:56<04:58,  1.50it/s]\n",
      "44%|████▍     | 356/802 [03:57<04:58,  1.50it/s]\n",
      "45%|████▍     | 357/802 [03:57<04:57,  1.50it/s]\n",
      "45%|████▍     | 358/802 [03:58<04:56,  1.50it/s]\n",
      "45%|████▍     | 359/802 [03:59<04:56,  1.50it/s]\n",
      "45%|████▍     | 360/802 [03:59<04:55,  1.50it/s]\n",
      "45%|████▌     | 361/802 [04:00<04:54,  1.50it/s]\n",
      "45%|████▌     | 362/802 [04:01<04:54,  1.50it/s]\n",
      "45%|████▌     | 363/802 [04:01<04:53,  1.50it/s]\n",
      "45%|████▌     | 364/802 [04:02<04:52,  1.50it/s]\n",
      "46%|████▌     | 365/802 [04:03<04:51,  1.50it/s]\n",
      "46%|████▌     | 366/802 [04:03<04:50,  1.50it/s]\n",
      "46%|████▌     | 367/802 [04:04<04:50,  1.50it/s]\n",
      "46%|████▌     | 368/802 [04:05<04:49,  1.50it/s]\n",
      "46%|████▌     | 369/802 [04:05<04:49,  1.50it/s]\n",
      "46%|████▌     | 370/802 [04:06<04:49,  1.49it/s]\n",
      "46%|████▋     | 371/802 [04:07<04:48,  1.49it/s]\n",
      "46%|████▋     | 372/802 [04:07<04:47,  1.50it/s]\n",
      "47%|████▋     | 373/802 [04:08<04:47,  1.49it/s]\n",
      "47%|████▋     | 374/802 [04:09<04:45,  1.50it/s]\n",
      "47%|████▋     | 375/802 [04:09<04:45,  1.49it/s]\n",
      "47%|████▋     | 376/802 [04:10<04:45,  1.49it/s]\n",
      "47%|████▋     | 377/802 [04:11<04:44,  1.49it/s]\n",
      "47%|████▋     | 378/802 [04:11<04:43,  1.49it/s]\n",
      "47%|████▋     | 379/802 [04:12<04:43,  1.49it/s]\n",
      "47%|████▋     | 380/802 [04:13<04:42,  1.50it/s]\n",
      "48%|████▊     | 381/802 [04:13<04:41,  1.50it/s]\n",
      "48%|████▊     | 382/802 [04:14<04:41,  1.49it/s]\n",
      "48%|████▊     | 383/802 [04:15<04:40,  1.49it/s]\n",
      "48%|████▊     | 384/802 [04:15<04:39,  1.49it/s]\n",
      "48%|████▊     | 385/802 [04:16<04:39,  1.49it/s]\n",
      "48%|████▊     | 386/802 [04:17<04:38,  1.50it/s]\n",
      "48%|████▊     | 387/802 [04:17<04:37,  1.50it/s]\n",
      "48%|████▊     | 388/802 [04:18<04:36,  1.50it/s]\n",
      "49%|████▊     | 389/802 [04:19<04:35,  1.50it/s]\n",
      "49%|████▊     | 390/802 [04:19<04:34,  1.50it/s]\n",
      "49%|████▉     | 391/802 [04:20<04:34,  1.50it/s]\n",
      "49%|████▉     | 392/802 [04:21<04:33,  1.50it/s]\n",
      "49%|████▉     | 393/802 [04:21<04:32,  1.50it/s]\n",
      "49%|████▉     | 394/802 [04:22<04:32,  1.50it/s]\n",
      "49%|████▉     | 395/802 [04:23<04:31,  1.50it/s]\n",
      "49%|████▉     | 396/802 [04:23<04:31,  1.50it/s]\n",
      "50%|████▉     | 397/802 [04:24<04:30,  1.50it/s]\n",
      "50%|████▉     | 398/802 [04:25<04:29,  1.50it/s]\n",
      "50%|████▉     | 399/802 [04:25<04:29,  1.49it/s]\n",
      "50%|████▉     | 400/802 [04:26<04:28,  1.49it/s]\n",
      "50%|█████     | 401/802 [04:27<04:12,  1.59it/s]\n",
      "{'loss': 3.26, 'learning_rate': 4.0100000000000006e-05, 'epoch': 1.0}\n",
      "50%|█████     | 401/802 [04:27<04:12,  1.59it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "Num examples = 357\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 357\n",
      "  Batch size = 64\n",
      "Batch size = 64\n",
      "0%|          | 0/6 [00:00<?, ?it/s]#033[A\n",
      "33%|███▎      | 2/6 [00:01<00:03,  1.08it/s]#033[A\n",
      "50%|█████     | 3/6 [00:03<00:03,  1.31s/it]#033[A\n",
      "67%|██████▋   | 4/6 [00:05<00:03,  1.51s/it]#033[A\n",
      "83%|████████▎ | 5/6 [00:07<00:01,  1.63s/it]#033[A\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]#033[A\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "#033[A\n",
      "{'eval_loss': 2.3014016151428223, 'eval_acc': 0.4481792717086835, 'eval_log_loss': 2.9803902148023336, 'eval_runtime': 10.3352, 'eval_samples_per_second': 34.542, 'eval_steps_per_second': 0.581, 'epoch': 1.0}\n",
      "50%|█████     | 401/802 [04:37<04:12,  1.59it/s]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]#033[A\n",
      "#033[A\n",
      "50%|█████     | 402/802 [04:38<24:57,  3.74s/it]\n",
      "50%|█████     | 403/802 [04:38<18:44,  2.82s/it]\n",
      "50%|█████     | 404/802 [04:39<14:24,  2.17s/it]\n",
      "50%|█████     | 405/802 [04:40<11:23,  1.72s/it]\n",
      "51%|█████     | 406/802 [04:40<09:16,  1.40s/it]\n",
      "51%|█████     | 407/802 [04:41<07:48,  1.18s/it]\n",
      "51%|█████     | 408/802 [04:42<06:45,  1.03s/it]\n",
      "51%|█████     | 409/802 [04:42<06:01,  1.09it/s]\n",
      "51%|█████     | 410/802 [04:43<05:31,  1.18it/s]\n",
      "51%|█████     | 411/802 [04:44<05:09,  1.26it/s]\n",
      "51%|█████▏    | 412/802 [04:44<04:54,  1.32it/s]\n",
      "51%|█████▏    | 413/802 [04:45<04:43,  1.37it/s]\n",
      "52%|█████▏    | 414/802 [04:46<04:35,  1.41it/s]\n",
      "52%|█████▏    | 415/802 [04:46<04:30,  1.43it/s]\n",
      "52%|█████▏    | 416/802 [04:47<04:25,  1.45it/s]\n",
      "52%|█████▏    | 417/802 [04:48<04:23,  1.46it/s]\n",
      "52%|█████▏    | 418/802 [04:48<04:20,  1.47it/s]\n",
      "52%|█████▏    | 419/802 [04:49<04:19,  1.48it/s]\n",
      "52%|█████▏    | 420/802 [04:50<04:17,  1.49it/s]\n",
      "52%|█████▏    | 421/802 [04:50<04:15,  1.49it/s]\n",
      "53%|█████▎    | 422/802 [04:51<04:14,  1.49it/s]\n",
      "53%|█████▎    | 423/802 [04:52<04:13,  1.49it/s]\n",
      "53%|█████▎    | 424/802 [04:52<04:12,  1.49it/s]\n",
      "53%|█████▎    | 425/802 [04:53<04:12,  1.49it/s]\n",
      "53%|█████▎    | 426/802 [04:54<04:11,  1.50it/s]\n",
      "53%|█████▎    | 427/802 [04:54<04:10,  1.50it/s]\n",
      "53%|█████▎    | 428/802 [04:55<04:10,  1.50it/s]\n",
      "53%|█████▎    | 429/802 [04:56<04:09,  1.50it/s]\n",
      "54%|█████▎    | 430/802 [04:56<04:08,  1.50it/s]\n",
      "54%|█████▎    | 431/802 [04:57<04:08,  1.49it/s]\n",
      "54%|█████▍    | 432/802 [04:58<04:07,  1.50it/s]\n",
      "54%|█████▍    | 433/802 [04:58<04:06,  1.49it/s]\n",
      "54%|█████▍    | 434/802 [04:59<04:06,  1.50it/s]\n",
      "54%|█████▍    | 435/802 [05:00<04:05,  1.50it/s]\n",
      "54%|█████▍    | 436/802 [05:00<04:04,  1.50it/s]\n",
      "54%|█████▍    | 437/802 [05:01<04:04,  1.50it/s]\n",
      "55%|█████▍    | 438/802 [05:02<04:03,  1.49it/s]\n",
      "55%|█████▍    | 439/802 [05:02<04:02,  1.50it/s]\n",
      "55%|█████▍    | 440/802 [05:03<04:02,  1.50it/s]\n",
      "55%|█████▍    | 441/802 [05:04<04:01,  1.49it/s]\n",
      "55%|█████▌    | 442/802 [05:04<04:00,  1.50it/s]\n",
      "55%|█████▌    | 443/802 [05:05<04:00,  1.50it/s]\n",
      "55%|█████▌    | 444/802 [05:06<03:59,  1.50it/s]\n",
      "55%|█████▌    | 445/802 [05:06<03:58,  1.50it/s]\n",
      "56%|█████▌    | 446/802 [05:07<03:57,  1.50it/s]\n",
      "56%|█████▌    | 447/802 [05:08<03:57,  1.50it/s]\n",
      "56%|█████▌    | 448/802 [05:08<03:56,  1.50it/s]\n",
      "56%|█████▌    | 449/802 [05:09<03:55,  1.50it/s]\n",
      "56%|█████▌    | 450/802 [05:10<03:55,  1.50it/s]\n",
      "56%|█████▌    | 451/802 [05:10<03:54,  1.50it/s]\n",
      "56%|█████▋    | 452/802 [05:11<03:53,  1.50it/s]\n",
      "56%|█████▋    | 453/802 [05:12<03:53,  1.50it/s]\n",
      "57%|█████▋    | 454/802 [05:12<03:52,  1.50it/s]\n",
      "57%|█████▋    | 455/802 [05:13<03:51,  1.50it/s]\n",
      "57%|█████▋    | 456/802 [05:14<03:51,  1.50it/s]\n",
      "57%|█████▋    | 457/802 [05:14<03:50,  1.50it/s]\n",
      "57%|█████▋    | 458/802 [05:15<03:49,  1.50it/s]\n",
      "57%|█████▋    | 459/802 [05:16<03:49,  1.49it/s]\n",
      "57%|█████▋    | 460/802 [05:16<03:48,  1.50it/s]\n",
      "57%|█████▋    | 461/802 [05:17<03:48,  1.50it/s]\n",
      "58%|█████▊    | 462/802 [05:18<03:47,  1.49it/s]\n",
      "58%|█████▊    | 463/802 [05:18<03:46,  1.50it/s]\n",
      "58%|█████▊    | 464/802 [05:19<03:46,  1.49it/s]\n",
      "58%|█████▊    | 465/802 [05:20<03:45,  1.49it/s]\n",
      "58%|█████▊    | 466/802 [05:20<03:44,  1.49it/s]\n",
      "58%|█████▊    | 467/802 [05:21<03:44,  1.50it/s]\n",
      "58%|█████▊    | 468/802 [05:22<03:43,  1.49it/s]\n",
      "58%|█████▊    | 469/802 [05:22<03:42,  1.50it/s]\n",
      "59%|█████▊    | 470/802 [05:23<03:42,  1.50it/s]\n",
      "59%|█████▊    | 471/802 [05:24<03:41,  1.50it/s]\n",
      "59%|█████▉    | 472/802 [05:24<03:40,  1.49it/s]\n",
      "59%|█████▉    | 473/802 [05:25<03:39,  1.50it/s]\n",
      "59%|█████▉    | 474/802 [05:26<03:39,  1.49it/s]\n",
      "59%|█████▉    | 475/802 [05:26<03:39,  1.49it/s]\n",
      "59%|█████▉    | 476/802 [05:27<03:37,  1.50it/s]\n",
      "59%|█████▉    | 477/802 [05:28<03:37,  1.49it/s]\n",
      "60%|█████▉    | 478/802 [05:28<03:36,  1.49it/s]\n",
      "60%|█████▉    | 479/802 [05:29<03:35,  1.50it/s]\n",
      "60%|█████▉    | 480/802 [05:30<03:35,  1.50it/s]\n",
      "60%|█████▉    | 481/802 [05:30<03:34,  1.50it/s]\n",
      "60%|██████    | 482/802 [05:31<03:34,  1.49it/s]\n",
      "60%|██████    | 483/802 [05:32<03:33,  1.49it/s]\n",
      "60%|██████    | 484/802 [05:32<03:32,  1.49it/s]\n",
      "60%|██████    | 485/802 [05:33<03:32,  1.49it/s]\n",
      "61%|██████    | 486/802 [05:34<03:31,  1.50it/s]\n",
      "61%|██████    | 487/802 [05:34<03:30,  1.50it/s]\n",
      "61%|██████    | 488/802 [05:35<03:30,  1.50it/s]\n",
      "61%|██████    | 489/802 [05:36<03:29,  1.50it/s]\n",
      "61%|██████    | 490/802 [05:36<03:28,  1.50it/s]\n",
      "61%|██████    | 491/802 [05:37<03:27,  1.50it/s]\n",
      "61%|██████▏   | 492/802 [05:38<03:27,  1.50it/s]\n",
      "61%|██████▏   | 493/802 [05:38<03:26,  1.49it/s]\n",
      "62%|██████▏   | 494/802 [05:39<03:25,  1.50it/s]\n",
      "62%|██████▏   | 495/802 [05:40<03:24,  1.50it/s]\n",
      "62%|██████▏   | 496/802 [05:40<03:24,  1.50it/s]\n",
      "62%|██████▏   | 497/802 [05:41<03:23,  1.50it/s]\n",
      "62%|██████▏   | 498/802 [05:42<03:23,  1.50it/s]\n",
      "62%|██████▏   | 499/802 [05:42<03:22,  1.50it/s]\n",
      "62%|██████▏   | 500/802 [05:43<03:21,  1.50it/s]\n",
      "Saving model checkpoint to /opt/ml/model/checkpoint-500\n",
      "Saving model checkpoint to /opt/ml/model/checkpoint-500\n",
      "Configuration saved in /opt/ml/model/checkpoint-500/config.json\n",
      "Configuration saved in /opt/ml/model/checkpoint-500/config.json\n",
      "Model weights saved in /opt/ml/model/checkpoint-500/pytorch_model.bin\n",
      "Model weights saved in /opt/ml/model/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /opt/ml/model/checkpoint-500/tokenizer_config.json\n",
      "tokenizer config file saved in /opt/ml/model/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /opt/ml/model/checkpoint-500/special_tokens_map.json\n",
      "Special tokens file saved in /opt/ml/model/checkpoint-500/special_tokens_map.json\n",
      "62%|██████▏   | 501/802 [05:46<06:05,  1.22s/it]\n",
      "63%|██████▎   | 502/802 [05:46<05:15,  1.05s/it]\n",
      "63%|██████▎   | 503/802 [05:47<04:39,  1.07it/s]\n",
      "63%|██████▎   | 504/802 [05:48<04:15,  1.17it/s]\n",
      "63%|██████▎   | 505/802 [05:48<03:57,  1.25it/s]\n",
      "63%|██████▎   | 506/802 [05:49<03:45,  1.31it/s]\n",
      "63%|██████▎   | 507/802 [05:50<03:36,  1.36it/s]\n",
      "63%|██████▎   | 508/802 [05:50<03:29,  1.40it/s]\n",
      "63%|██████▎   | 509/802 [05:51<03:24,  1.43it/s]\n",
      "64%|██████▎   | 510/802 [05:52<03:21,  1.45it/s]\n",
      "64%|██████▎   | 511/802 [05:52<03:19,  1.46it/s]\n",
      "64%|██████▍   | 512/802 [05:53<03:16,  1.47it/s]\n",
      "64%|██████▍   | 513/802 [05:54<03:15,  1.48it/s]\n",
      "64%|██████▍   | 514/802 [05:54<03:14,  1.48it/s]\n",
      "64%|██████▍   | 515/802 [05:55<03:12,  1.49it/s]\n",
      "64%|██████▍   | 516/802 [05:56<03:11,  1.49it/s]\n",
      "64%|██████▍   | 517/802 [05:56<03:11,  1.49it/s]\n",
      "65%|██████▍   | 518/802 [05:57<03:09,  1.50it/s]\n",
      "65%|██████▍   | 519/802 [05:58<03:09,  1.49it/s]\n",
      "65%|██████▍   | 520/802 [05:58<03:08,  1.50it/s]\n",
      "65%|██████▍   | 521/802 [05:59<03:07,  1.50it/s]\n",
      "65%|██████▌   | 522/802 [06:00<03:07,  1.50it/s]\n",
      "65%|██████▌   | 523/802 [06:00<03:06,  1.50it/s]\n",
      "65%|██████▌   | 524/802 [06:01<03:05,  1.50it/s]\n",
      "65%|██████▌   | 525/802 [06:02<03:05,  1.50it/s]\n",
      "66%|██████▌   | 526/802 [06:02<03:04,  1.50it/s]\n",
      "66%|██████▌   | 527/802 [06:03<03:03,  1.50it/s]\n",
      "66%|██████▌   | 528/802 [06:04<03:03,  1.50it/s]\n",
      "66%|██████▌   | 529/802 [06:04<03:02,  1.50it/s]\n",
      "66%|██████▌   | 530/802 [06:05<03:01,  1.50it/s]\n",
      "66%|██████▌   | 531/802 [06:06<03:00,  1.50it/s]\n",
      "66%|██████▋   | 532/802 [06:06<03:00,  1.50it/s]\n",
      "66%|██████▋   | 533/802 [06:07<02:59,  1.50it/s]\n",
      "67%|██████▋   | 534/802 [06:08<02:59,  1.50it/s]\n",
      "67%|██████▋   | 535/802 [06:08<02:58,  1.50it/s]\n",
      "67%|██████▋   | 536/802 [06:09<02:57,  1.50it/s]\n",
      "67%|██████▋   | 537/802 [06:10<02:56,  1.50it/s]\n",
      "67%|██████▋   | 538/802 [06:10<02:56,  1.50it/s]\n",
      "67%|██████▋   | 539/802 [06:11<02:55,  1.50it/s]\n",
      "67%|██████▋   | 540/802 [06:12<02:55,  1.50it/s]\n",
      "67%|██████▋   | 541/802 [06:12<02:54,  1.50it/s]\n",
      "68%|██████▊   | 542/802 [06:13<02:53,  1.50it/s]\n",
      "68%|██████▊   | 543/802 [06:14<02:53,  1.50it/s]\n",
      "68%|██████▊   | 544/802 [06:14<02:52,  1.50it/s]\n",
      "68%|██████▊   | 545/802 [06:15<02:51,  1.50it/s]\n",
      "68%|██████▊   | 546/802 [06:16<02:51,  1.50it/s]\n",
      "68%|██████▊   | 547/802 [06:16<02:50,  1.50it/s]\n",
      "68%|██████▊   | 548/802 [06:17<02:49,  1.50it/s]\n",
      "68%|██████▊   | 549/802 [06:18<02:49,  1.50it/s]\n",
      "69%|██████▊   | 550/802 [06:18<02:48,  1.50it/s]\n",
      "69%|██████▊   | 551/802 [06:19<02:47,  1.49it/s]\n",
      "69%|██████▉   | 552/802 [06:20<02:47,  1.50it/s]\n",
      "69%|██████▉   | 553/802 [06:20<02:46,  1.50it/s]\n",
      "69%|██████▉   | 554/802 [06:21<02:45,  1.50it/s]\n",
      "69%|██████▉   | 555/802 [06:22<02:45,  1.50it/s]\n",
      "69%|██████▉   | 556/802 [06:22<02:44,  1.50it/s]\n",
      "69%|██████▉   | 557/802 [06:23<02:43,  1.50it/s]\n",
      "70%|██████▉   | 558/802 [06:24<02:43,  1.50it/s]\n",
      "70%|██████▉   | 559/802 [06:24<02:42,  1.50it/s]\n",
      "70%|██████▉   | 560/802 [06:25<02:42,  1.49it/s]\n",
      "70%|██████▉   | 561/802 [06:26<02:41,  1.50it/s]\n",
      "70%|███████   | 562/802 [06:26<02:40,  1.49it/s]\n",
      "70%|███████   | 563/802 [06:27<02:39,  1.49it/s]\n",
      "70%|███████   | 564/802 [06:28<02:39,  1.49it/s]\n",
      "70%|███████   | 565/802 [06:28<02:38,  1.50it/s]\n",
      "71%|███████   | 566/802 [06:29<02:37,  1.50it/s]\n",
      "71%|███████   | 567/802 [06:30<02:37,  1.49it/s]\n",
      "71%|███████   | 568/802 [06:30<02:36,  1.49it/s]\n",
      "71%|███████   | 569/802 [06:31<02:35,  1.49it/s]\n",
      "71%|███████   | 570/802 [06:32<02:35,  1.50it/s]\n",
      "71%|███████   | 571/802 [06:32<02:34,  1.50it/s]\n",
      "71%|███████▏  | 572/802 [06:33<02:33,  1.50it/s]\n",
      "71%|███████▏  | 573/802 [06:34<02:33,  1.49it/s]\n",
      "72%|███████▏  | 574/802 [06:34<02:32,  1.49it/s]\n",
      "72%|███████▏  | 575/802 [06:35<02:31,  1.49it/s]\n",
      "72%|███████▏  | 576/802 [06:36<02:31,  1.49it/s]\n",
      "72%|███████▏  | 577/802 [06:36<02:30,  1.50it/s]\n",
      "72%|███████▏  | 578/802 [06:37<02:29,  1.50it/s]\n",
      "72%|███████▏  | 579/802 [06:38<02:29,  1.50it/s]\n",
      "72%|███████▏  | 580/802 [06:38<02:28,  1.49it/s]\n",
      "72%|███████▏  | 581/802 [06:39<02:27,  1.49it/s]\n",
      "73%|███████▎  | 582/802 [06:40<02:27,  1.49it/s]\n",
      "73%|███████▎  | 583/802 [06:40<02:26,  1.49it/s]\n",
      "73%|███████▎  | 584/802 [06:41<02:25,  1.49it/s]\n",
      "73%|███████▎  | 585/802 [06:42<02:25,  1.50it/s]\n",
      "73%|███████▎  | 586/802 [06:42<02:24,  1.49it/s]\n",
      "73%|███████▎  | 587/802 [06:43<02:23,  1.50it/s]\n",
      "73%|███████▎  | 588/802 [06:44<02:23,  1.50it/s]\n",
      "73%|███████▎  | 589/802 [06:44<02:22,  1.50it/s]\n",
      "74%|███████▎  | 590/802 [06:45<02:21,  1.50it/s]\n",
      "74%|███████▎  | 591/802 [06:46<02:21,  1.50it/s]\n",
      "74%|███████▍  | 592/802 [06:46<02:20,  1.50it/s]\n",
      "74%|███████▍  | 593/802 [06:47<02:19,  1.50it/s]\n",
      "74%|███████▍  | 594/802 [06:48<02:18,  1.50it/s]\n",
      "74%|███████▍  | 595/802 [06:48<02:18,  1.50it/s]\n",
      "74%|███████▍  | 596/802 [06:49<02:17,  1.50it/s]\n",
      "74%|███████▍  | 597/802 [06:50<02:17,  1.50it/s]\n",
      "75%|███████▍  | 598/802 [06:50<02:16,  1.49it/s]\n",
      "75%|███████▍  | 599/802 [06:51<02:15,  1.50it/s]\n",
      "75%|███████▍  | 600/802 [06:52<02:15,  1.50it/s]\n",
      "75%|███████▍  | 601/802 [06:52<02:14,  1.50it/s]\n",
      "75%|███████▌  | 602/802 [06:53<02:13,  1.50it/s]\n",
      "75%|███████▌  | 603/802 [06:54<02:13,  1.50it/s]\n",
      "75%|███████▌  | 604/802 [06:54<02:12,  1.50it/s]\n",
      "75%|███████▌  | 605/802 [06:55<02:11,  1.50it/s]\n",
      "76%|███████▌  | 606/802 [06:56<02:11,  1.50it/s]\n",
      "76%|███████▌  | 607/802 [06:56<02:10,  1.50it/s]\n",
      "76%|███████▌  | 608/802 [06:57<02:09,  1.50it/s]\n",
      "76%|███████▌  | 609/802 [06:58<02:08,  1.50it/s]\n",
      "76%|███████▌  | 610/802 [06:58<02:08,  1.49it/s]\n",
      "76%|███████▌  | 611/802 [06:59<02:07,  1.50it/s]\n",
      "76%|███████▋  | 612/802 [07:00<02:06,  1.50it/s]\n",
      "76%|███████▋  | 613/802 [07:00<02:06,  1.50it/s]\n",
      "77%|███████▋  | 614/802 [07:01<02:05,  1.50it/s]\n",
      "77%|███████▋  | 615/802 [07:02<02:05,  1.49it/s]\n",
      "77%|███████▋  | 616/802 [07:02<02:04,  1.50it/s]\n",
      "77%|███████▋  | 617/802 [07:03<02:03,  1.50it/s]\n",
      "77%|███████▋  | 618/802 [07:04<02:02,  1.50it/s]\n",
      "77%|███████▋  | 619/802 [07:04<02:02,  1.50it/s]\n",
      "77%|███████▋  | 620/802 [07:05<02:01,  1.50it/s]\n",
      "77%|███████▋  | 621/802 [07:06<02:00,  1.50it/s]\n",
      "78%|███████▊  | 622/802 [07:06<02:00,  1.49it/s]\n",
      "78%|███████▊  | 623/802 [07:07<01:59,  1.50it/s]\n",
      "78%|███████▊  | 624/802 [07:08<01:59,  1.49it/s]\n",
      "78%|███████▊  | 625/802 [07:08<01:58,  1.50it/s]\n",
      "78%|███████▊  | 626/802 [07:09<01:57,  1.49it/s]\n",
      "78%|███████▊  | 627/802 [07:10<01:56,  1.50it/s]\n",
      "78%|███████▊  | 628/802 [07:10<01:56,  1.50it/s]\n",
      "78%|███████▊  | 629/802 [07:11<01:55,  1.50it/s]\n",
      "79%|███████▊  | 630/802 [07:12<01:54,  1.50it/s]\n",
      "79%|███████▊  | 631/802 [07:12<01:54,  1.50it/s]\n",
      "79%|███████▉  | 632/802 [07:13<01:53,  1.50it/s]\n",
      "79%|███████▉  | 633/802 [07:14<01:53,  1.49it/s]\n",
      "79%|███████▉  | 634/802 [07:14<01:52,  1.50it/s]\n",
      "79%|███████▉  | 635/802 [07:15<01:51,  1.50it/s]\n",
      "79%|███████▉  | 636/802 [07:16<01:51,  1.49it/s]\n",
      "79%|███████▉  | 637/802 [07:16<01:50,  1.50it/s]\n",
      "80%|███████▉  | 638/802 [07:17<01:49,  1.50it/s]\n",
      "80%|███████▉  | 639/802 [07:18<01:48,  1.50it/s]\n",
      "80%|███████▉  | 640/802 [07:18<01:48,  1.50it/s]\n",
      "80%|███████▉  | 641/802 [07:19<01:47,  1.50it/s]\n",
      "80%|████████  | 642/802 [07:20<01:46,  1.50it/s]\n",
      "80%|████████  | 643/802 [07:20<01:46,  1.50it/s]\n",
      "80%|████████  | 644/802 [07:21<01:45,  1.50it/s]\n",
      "80%|████████  | 645/802 [07:22<01:44,  1.50it/s]\n",
      "81%|████████  | 646/802 [07:22<01:44,  1.50it/s]\n",
      "81%|████████  | 647/802 [07:23<01:43,  1.50it/s]\n",
      "81%|████████  | 648/802 [07:24<01:42,  1.50it/s]\n",
      "81%|████████  | 649/802 [07:24<01:42,  1.49it/s]\n",
      "81%|████████  | 650/802 [07:25<01:41,  1.50it/s]\n",
      "81%|████████  | 651/802 [07:26<01:40,  1.50it/s]\n",
      "81%|████████▏ | 652/802 [07:26<01:40,  1.49it/s]\n",
      "81%|████████▏ | 653/802 [07:27<01:39,  1.50it/s]\n",
      "82%|████████▏ | 654/802 [07:28<01:38,  1.50it/s]\n",
      "82%|████████▏ | 655/802 [07:28<01:38,  1.49it/s]\n",
      "82%|████████▏ | 656/802 [07:29<01:37,  1.49it/s]\n",
      "82%|████████▏ | 657/802 [07:30<01:36,  1.50it/s]\n",
      "82%|████████▏ | 658/802 [07:30<01:36,  1.50it/s]\n",
      "82%|████████▏ | 659/802 [07:31<01:35,  1.50it/s]\n",
      "82%|████████▏ | 660/802 [07:32<01:35,  1.49it/s]\n",
      "82%|████████▏ | 661/802 [07:32<01:34,  1.49it/s]\n",
      "83%|████████▎ | 662/802 [07:33<01:33,  1.50it/s]\n",
      "83%|████████▎ | 663/802 [07:34<01:32,  1.50it/s]\n",
      "83%|████████▎ | 664/802 [07:35<01:32,  1.50it/s]\n",
      "83%|████████▎ | 665/802 [07:35<01:31,  1.50it/s]\n",
      "83%|████████▎ | 666/802 [07:36<01:30,  1.49it/s]\n",
      "83%|████████▎ | 667/802 [07:37<01:30,  1.50it/s]\n",
      "83%|████████▎ | 668/802 [07:37<01:29,  1.50it/s]\n",
      "83%|████████▎ | 669/802 [07:38<01:29,  1.49it/s]\n",
      "84%|████████▎ | 670/802 [07:39<01:28,  1.49it/s]\n",
      "84%|████████▎ | 671/802 [07:39<01:27,  1.49it/s]\n",
      "84%|████████▍ | 672/802 [07:40<01:26,  1.50it/s]\n",
      "84%|████████▍ | 673/802 [07:41<01:26,  1.50it/s]\n",
      "84%|████████▍ | 674/802 [07:41<01:25,  1.50it/s]\n",
      "84%|████████▍ | 675/802 [07:42<01:24,  1.50it/s]\n",
      "84%|████████▍ | 676/802 [07:43<01:24,  1.49it/s]\n",
      "84%|████████▍ | 677/802 [07:43<01:23,  1.50it/s]\n",
      "85%|████████▍ | 678/802 [07:44<01:23,  1.49it/s]\n",
      "85%|████████▍ | 679/802 [07:45<01:22,  1.49it/s]\n",
      "85%|████████▍ | 680/802 [07:45<01:21,  1.49it/s]\n",
      "85%|████████▍ | 681/802 [07:46<01:21,  1.49it/s]\n",
      "85%|████████▌ | 682/802 [07:47<01:20,  1.49it/s]\n",
      "85%|████████▌ | 683/802 [07:47<01:19,  1.50it/s]\n",
      "85%|████████▌ | 684/802 [07:48<01:18,  1.50it/s]\n",
      "85%|████████▌ | 685/802 [07:49<01:18,  1.50it/s]\n",
      "86%|████████▌ | 686/802 [07:49<01:17,  1.50it/s]\n",
      "86%|████████▌ | 687/802 [07:50<01:16,  1.50it/s]\n",
      "86%|████████▌ | 688/802 [07:51<01:16,  1.50it/s]\n",
      "86%|████████▌ | 689/802 [07:51<01:15,  1.50it/s]\n",
      "86%|████████▌ | 690/802 [07:52<01:14,  1.49it/s]\n",
      "86%|████████▌ | 691/802 [07:53<01:14,  1.50it/s]\n",
      "86%|████████▋ | 692/802 [07:53<01:13,  1.49it/s]\n",
      "86%|████████▋ | 693/802 [07:54<01:12,  1.50it/s]\n",
      "87%|████████▋ | 694/802 [07:55<01:12,  1.50it/s]\n",
      "87%|████████▋ | 695/802 [07:55<01:11,  1.50it/s]\n",
      "87%|████████▋ | 696/802 [07:56<01:10,  1.50it/s]\n",
      "87%|████████▋ | 697/802 [07:57<01:10,  1.50it/s]\n",
      "87%|████████▋ | 698/802 [07:57<01:09,  1.50it/s]\n",
      "87%|████████▋ | 699/802 [07:58<01:08,  1.50it/s]\n",
      "87%|████████▋ | 700/802 [07:59<01:08,  1.50it/s]\n",
      "87%|████████▋ | 701/802 [07:59<01:07,  1.50it/s]\n",
      "88%|████████▊ | 702/802 [08:00<01:06,  1.49it/s]\n",
      "88%|████████▊ | 703/802 [08:01<01:06,  1.49it/s]\n",
      "88%|████████▊ | 704/802 [08:01<01:05,  1.50it/s]\n",
      "88%|████████▊ | 705/802 [08:02<01:04,  1.50it/s]\n",
      "88%|████████▊ | 706/802 [08:03<01:04,  1.49it/s]\n",
      "88%|████████▊ | 707/802 [08:03<01:03,  1.50it/s]\n",
      "88%|████████▊ | 708/802 [08:04<01:02,  1.49it/s]\n",
      "88%|████████▊ | 709/802 [08:05<01:02,  1.50it/s]\n",
      "89%|████████▊ | 710/802 [08:05<01:01,  1.50it/s]\n",
      "89%|████████▊ | 711/802 [08:06<01:00,  1.50it/s]\n",
      "89%|████████▉ | 712/802 [08:07<01:00,  1.50it/s]\n",
      "89%|████████▉ | 713/802 [08:07<00:59,  1.50it/s]\n",
      "89%|████████▉ | 714/802 [08:08<00:58,  1.50it/s]\n",
      "89%|████████▉ | 715/802 [08:09<00:58,  1.50it/s]\n",
      "89%|████████▉ | 716/802 [08:09<00:57,  1.50it/s]\n",
      "89%|████████▉ | 717/802 [08:10<00:56,  1.50it/s]\n",
      "90%|████████▉ | 718/802 [08:11<00:56,  1.50it/s]\n",
      "90%|████████▉ | 719/802 [08:11<00:55,  1.50it/s]\n",
      "90%|████████▉ | 720/802 [08:12<00:54,  1.50it/s]\n",
      "90%|████████▉ | 721/802 [08:13<00:54,  1.50it/s]\n",
      "90%|█████████ | 722/802 [08:13<00:53,  1.49it/s]\n",
      "90%|█████████ | 723/802 [08:14<00:52,  1.50it/s]\n",
      "90%|█████████ | 724/802 [08:15<00:52,  1.49it/s]\n",
      "90%|█████████ | 725/802 [08:15<00:51,  1.49it/s]\n",
      "91%|█████████ | 726/802 [08:16<00:50,  1.49it/s]\n",
      "91%|█████████ | 727/802 [08:17<00:50,  1.50it/s]\n",
      "91%|█████████ | 728/802 [08:17<00:49,  1.50it/s]\n",
      "91%|█████████ | 729/802 [08:18<00:48,  1.49it/s]\n",
      "91%|█████████ | 730/802 [08:19<00:48,  1.50it/s]\n",
      "91%|█████████ | 731/802 [08:19<00:47,  1.50it/s]\n",
      "91%|█████████▏| 732/802 [08:20<00:46,  1.50it/s]\n",
      "91%|█████████▏| 733/802 [08:21<00:46,  1.50it/s]\n",
      "92%|█████████▏| 734/802 [08:21<00:45,  1.50it/s]\n",
      "92%|█████████▏| 735/802 [08:22<00:44,  1.50it/s]\n",
      "92%|█████████▏| 736/802 [08:23<00:44,  1.50it/s]\n",
      "92%|█████████▏| 737/802 [08:23<00:43,  1.50it/s]\n",
      "92%|█████████▏| 738/802 [08:24<00:42,  1.50it/s]\n",
      "92%|█████████▏| 739/802 [08:25<00:42,  1.49it/s]\n",
      "92%|█████████▏| 740/802 [08:25<00:41,  1.50it/s]\n",
      "92%|█████████▏| 741/802 [08:26<00:40,  1.50it/s]\n",
      "93%|█████████▎| 742/802 [08:27<00:40,  1.50it/s]\n",
      "93%|█████████▎| 743/802 [08:27<00:39,  1.50it/s]\n",
      "93%|█████████▎| 744/802 [08:28<00:38,  1.50it/s]\n",
      "93%|█████████▎| 745/802 [08:29<00:38,  1.50it/s]\n",
      "93%|█████████▎| 746/802 [08:29<00:37,  1.50it/s]\n",
      "93%|█████████▎| 747/802 [08:30<00:36,  1.50it/s]\n",
      "93%|█████████▎| 748/802 [08:31<00:36,  1.50it/s]\n",
      "93%|█████████▎| 749/802 [08:31<00:35,  1.50it/s]\n",
      "94%|█████████▎| 750/802 [08:32<00:34,  1.50it/s]\n",
      "94%|█████████▎| 751/802 [08:33<00:34,  1.50it/s]\n",
      "94%|█████████▍| 752/802 [08:33<00:33,  1.50it/s]\n",
      "94%|█████████▍| 753/802 [08:34<00:32,  1.49it/s]\n",
      "94%|█████████▍| 754/802 [08:35<00:32,  1.50it/s]\n",
      "94%|█████████▍| 755/802 [08:35<00:31,  1.49it/s]\n",
      "94%|█████████▍| 756/802 [08:36<00:30,  1.50it/s]\n",
      "94%|█████████▍| 757/802 [08:37<00:30,  1.49it/s]\n",
      "95%|█████████▍| 758/802 [08:37<00:29,  1.50it/s]\n",
      "95%|█████████▍| 759/802 [08:38<00:28,  1.50it/s]\n",
      "95%|█████████▍| 760/802 [08:39<00:28,  1.50it/s]\n",
      "95%|█████████▍| 761/802 [08:39<00:27,  1.49it/s]\n",
      "95%|█████████▌| 762/802 [08:40<00:26,  1.50it/s]\n",
      "95%|█████████▌| 763/802 [08:41<00:26,  1.50it/s]\n",
      "95%|█████████▌| 764/802 [08:41<00:25,  1.49it/s]\n",
      "95%|█████████▌| 765/802 [08:42<00:24,  1.49it/s]\n",
      "96%|█████████▌| 766/802 [08:43<00:24,  1.50it/s]\n",
      "96%|█████████▌| 767/802 [08:43<00:23,  1.49it/s]\n",
      "96%|█████████▌| 768/802 [08:44<00:22,  1.50it/s]\n",
      "96%|█████████▌| 769/802 [08:45<00:22,  1.50it/s]\n",
      "96%|█████████▌| 770/802 [08:45<00:21,  1.49it/s]\n",
      "96%|█████████▌| 771/802 [08:46<00:20,  1.49it/s]\n",
      "96%|█████████▋| 772/802 [08:47<00:20,  1.49it/s]\n",
      "96%|█████████▋| 773/802 [08:47<00:19,  1.49it/s]\n",
      "97%|█████████▋| 774/802 [08:48<00:18,  1.49it/s]\n",
      "97%|█████████▋| 775/802 [08:49<00:18,  1.50it/s]\n",
      "97%|█████████▋| 776/802 [08:49<00:17,  1.49it/s]\n",
      "97%|█████████▋| 777/802 [08:50<00:16,  1.49it/s]\n",
      "97%|█████████▋| 778/802 [08:51<00:16,  1.49it/s]\n",
      "97%|█████████▋| 779/802 [08:51<00:15,  1.50it/s]\n",
      "97%|█████████▋| 780/802 [08:52<00:14,  1.49it/s]\n",
      "97%|█████████▋| 781/802 [08:53<00:14,  1.49it/s]\n",
      "98%|█████████▊| 782/802 [08:53<00:13,  1.49it/s]\n",
      "98%|█████████▊| 783/802 [08:54<00:12,  1.50it/s]\n",
      "98%|█████████▊| 784/802 [08:55<00:12,  1.49it/s]\n",
      "98%|█████████▊| 785/802 [08:55<00:11,  1.49it/s]\n",
      "98%|█████████▊| 786/802 [08:56<00:10,  1.50it/s]\n",
      "98%|█████████▊| 787/802 [08:57<00:10,  1.49it/s]\n",
      "98%|█████████▊| 788/802 [08:57<00:09,  1.50it/s]\n",
      "98%|█████████▊| 789/802 [08:58<00:08,  1.49it/s]\n",
      "99%|█████████▊| 790/802 [08:59<00:08,  1.50it/s]\n",
      "99%|█████████▊| 791/802 [08:59<00:07,  1.50it/s]\n",
      "99%|█████████▉| 792/802 [09:00<00:06,  1.50it/s]\n",
      "99%|█████████▉| 793/802 [09:01<00:06,  1.50it/s]\n",
      "99%|█████████▉| 794/802 [09:01<00:05,  1.50it/s]\n",
      "99%|█████████▉| 795/802 [09:02<00:04,  1.50it/s]\n",
      "99%|█████████▉| 796/802 [09:03<00:04,  1.50it/s]\n",
      "99%|█████████▉| 797/802 [09:03<00:03,  1.50it/s]\n",
      "100%|█████████▉| 798/802 [09:04<00:02,  1.50it/s]\n",
      "100%|█████████▉| 799/802 [09:05<00:02,  1.50it/s]\n",
      "100%|█████████▉| 800/802 [09:05<00:01,  1.50it/s]\n",
      "100%|█████████▉| 801/802 [09:06<00:00,  1.49it/s]\n",
      "100%|██████████| 802/802 [09:07<00:00,  1.59it/s]\n",
      "{'loss': 1.9569, 'learning_rate': 0.0, 'epoch': 2.0}\n",
      "100%|██████████| 802/802 [09:07<00:00,  1.59it/s]\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 357\n",
      "Num examples = 357\n",
      "  Batch size = 64\n",
      "Batch size = 64\n",
      "0%|          | 0/6 [00:00<?, ?it/s]#033[A\n",
      "33%|███▎      | 2/6 [00:01<00:03,  1.08it/s]#033[A\n",
      "50%|█████     | 3/6 [00:03<00:03,  1.31s/it]#033[A\n",
      "67%|██████▋   | 4/6 [00:05<00:03,  1.51s/it]#033[A\n",
      "83%|████████▎ | 5/6 [00:07<00:01,  1.63s/it]#033[A\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]#033[A\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "#033[A\n",
      "{'eval_loss': 1.685948133468628, 'eval_acc': 0.5378151260504201, 'eval_log_loss': 2.7086470372519647, 'eval_runtime': 10.3672, 'eval_samples_per_second': 34.436, 'eval_steps_per_second': 0.579, 'epoch': 2.0}\n",
      "100%|██████████| 802/802 [09:17<00:00,  1.59it/s]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]#033[A\n",
      "#033[A\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "{'train_runtime': 557.5197, 'train_samples_per_second': 11.501, 'train_steps_per_second': 1.439, 'train_loss': 2.608466321987999, 'epoch': 2.0}\n",
      "100%|██████████| 802/802 [09:17<00:00,  1.59it/s]\n",
      "100%|██████████| 802/802 [09:17<00:00,  1.44it/s]\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 357\n",
      "Num examples = 357\n",
      "  Batch size = 64\n",
      "Batch size = 64\n",
      "0%|          | 0/6 [00:00<?, ?it/s]\n",
      "33%|███▎      | 2/6 [00:01<00:03,  1.08it/s]\n",
      "50%|█████     | 3/6 [00:03<00:03,  1.31s/it]\n",
      "67%|██████▋   | 4/6 [00:05<00:03,  1.52s/it]\n",
      "83%|████████▎ | 5/6 [00:07<00:01,  1.63s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.42s/it]\n",
      "--trainer.state.log_history--\n",
      "{'loss': 3.26, 'learning_rate': 4.0100000000000006e-05, 'epoch': 1.0, 'step': 401}\n",
      "{'eval_loss': 2.3014016151428223, 'eval_acc': 0.4481792717086835, 'eval_log_loss': 2.9803902148023336, 'eval_runtime': 10.3352, 'eval_samples_per_second': 34.542, 'eval_steps_per_second': 0.581, 'epoch': 1.0, 'step': 401}\n",
      "{'loss': 1.9569, 'learning_rate': 0.0, 'epoch': 2.0, 'step': 802}\n",
      "{'eval_loss': 1.685948133468628, 'eval_acc': 0.5378151260504201, 'eval_log_loss': 2.7086470372519647, 'eval_runtime': 10.3672, 'eval_samples_per_second': 34.436, 'eval_steps_per_second': 0.579, 'epoch': 2.0, 'step': 802}\n",
      "{'train_runtime': 557.5197, 'train_samples_per_second': 11.501, 'train_steps_per_second': 1.439, 'total_flos': 1687719429623808.0, 'train_loss': 2.608466321987999, 'epoch': 2.0, 'step': 802}\n",
      "{'eval_loss': 1.685948133468628, 'eval_acc': 0.5378151260504201, 'eval_log_loss': 2.7086470372519647, 'eval_runtime': 10.3699, 'eval_samples_per_second': 34.427, 'eval_steps_per_second': 0.579, 'epoch': 2.0, 'step': 802}\n",
      "--Eval result--\n",
      "{'eval_loss': 1.685948133468628, 'eval_acc': 0.5378151260504201, 'eval_log_loss': 2.7086470372519647, 'eval_runtime': 10.3699, 'eval_samples_per_second': 34.427, 'eval_steps_per_second': 0.579, 'epoch': 2.0}\n",
      "Saving model checkpoint to /opt/ml/model\n",
      "Saving model checkpoint to /opt/ml/model\n",
      "Configuration saved in /opt/ml/model/config.json\n",
      "Configuration saved in /opt/ml/model/config.json\n",
      "Model weights saved in /opt/ml/model/pytorch_model.bin\n",
      "Model weights saved in /opt/ml/model/pytorch_model.bin\n",
      "tokenizer config file saved in /opt/ml/model/tokenizer_config.json\n",
      "tokenizer config file saved in /opt/ml/model/tokenizer_config.json\n",
      "Special tokens file saved in /opt/ml/model/special_tokens_map.json\n",
      "Special tokens file saved in /opt/ml/model/special_tokens_map.json\n",
      "2024-06-11 19:23:06,435 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-06-11 19:23:06,435 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-06-11 19:23:06,435 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2024-06-11 19:23:13 Uploading - Uploading generated training model\n",
      "2024-06-11 19:23:56 Completed - Training job completed\n",
      "Training seconds: 868\n",
      "Billable seconds: 868\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "## Ideally this should run in parallel...kick off training jobs horizontally via Lambda\n",
    "# ..not sure if SageMaker allows multiple training instances though\n",
    "\n",
    "# source: https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-script-mode/pytorch-sagemaker-huggingface/huggingface_text_classification.ipynb\n",
    "# Helpful:\n",
    "# - https://stackoverflow.com/questions/76821347/sagemaker-experiment-tracking-duplication\n",
    "# - https://www.youtube.com/watch?v=kK1ohrpJFC0\n",
    "\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.experiments import Run\n",
    "\n",
    "# Hyperparameters which are passed into the training job\n",
    "# Memory error when train_batch_size = 32 for bert-base-uncased\n",
    "transformers_version = \"4.26\"\n",
    "pytorch_version = \"1.13\"\n",
    "python_version = \"py39\"\n",
    "instance_type = \"ml.g4dn.xlarge\"\n",
    "instance_count = 1\n",
    "\n",
    "# hyperparameter tuning: https://medium.com/distributed-computing-with-ray/hyperparameter-optimization-for-transformers-a-guide-c4e32c6c989b\n",
    "model_list = [\"bert-base-uncased\"] # [\"distilbert-base-uncased\", \"bert-base-uncased\"]\n",
    "epoch_list = [2] # [2, 3, 4]\n",
    "learning_rate_list = [5e-5] # [3e-5, 5e-5]\n",
    "weight_decay_list = [0] #[0, 0.3]\n",
    "for model in model_list:\n",
    "    for epoch in epoch_list:\n",
    "        for learning_rate in learning_rate_list:\n",
    "            for weight_decay in weight_decay_list:\n",
    "                hyperparameters = {\n",
    "                    \"epochs\": epoch,\n",
    "                    \"train_batch_size\": 8,\n",
    "                    \"model_name\": model,\n",
    "                    \"weight_decay\": weight_decay,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                }\n",
    "                with Run(\n",
    "                    experiment_name=experiment_name,\n",
    "                    sagemaker_session=Session(),\n",
    "                    run_name=f\"{model}-epoch-{epoch}-lr-{learning_rate}-wd-{str(weight_decay).replace('.','')}-{int(time.time())}\",\n",
    "                ) as run:\n",
    "\n",
    "                    # HuggingFace container in SageMaker\n",
    "                    huggingface_estimator = HuggingFace(\n",
    "                        entry_point=\"train.py\",\n",
    "                        source_dir=\"./scripts\", # reads requirements.txt file in scripts directory\n",
    "                        instance_type=instance_type,\n",
    "                        instance_count=instance_count,\n",
    "                        role=role,\n",
    "                        transformers_version=transformers_version,\n",
    "                        pytorch_version=pytorch_version,\n",
    "                        py_version=python_version,\n",
    "                        hyperparameters=hyperparameters,\n",
    "                        enable_sagemaker_metrics=True,\n",
    "                    )\n",
    "\n",
    "                    # starts training job in SageMaker\n",
    "                    huggingface_estimator.fit(\n",
    "                        inputs={\"train\": train_input_path, \"test\": test_input_path},\n",
    "                        wait=True,\n",
    "                    )\n",
    "\n",
    "                    # log parameter in SageMaker Experiments\n",
    "                    run.log_parameter(name=\"instance_type\", value=instance_type)\n",
    "                    run.log_parameter(name=\"instance_count\", value=instance_count)\n",
    "                    run.log_artifact(\n",
    "                        name=\"train\", value=train_input_path, is_output=False\n",
    "                    )\n",
    "                    run.log_artifact(\n",
    "                        name=\"test\", value=test_input_path, is_output=False\n",
    "                    )\n",
    "                    run.log_artifact(\n",
    "                        name=\"SageMaker.ModelArtifact\",\n",
    "                        value=huggingface_estimator.model_data,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete experiment in Sagemaker -- can't do this in console\n",
    "# source: https://docs.aws.amazon.com/sagemaker/latest/dg/experiments-cleanup.html - need to make a few modifications\n",
    "exp = Experiment.load(experiment_name=\"sector-classification-experiments-v0\", sagemaker_boto_client=sm)\n",
    "exp.delete_all(action=\"--force\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sector_class_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
