{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raga Tracing Sample Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-openai langchain-chroma langchain-community pypdf ragaai-catalyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bobrandt/workspaces/data-science-and-ml-models/apps/multi-agent-bot/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(s) set successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BotTest', 'BrokerBot', 'ForgeFAQ']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from ragaai_catalyst import RagaAICatalyst, Experiment, Dataset, Tracer, Evaluation\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "RAGA_ACCESS_KEY = os.getenv(\"RAGA_ACCESS_KEY\")\n",
    "RAGA_SECRET_KEY = os.getenv(\"RAGA_SECRET_KEY\")\n",
    "\n",
    "catalyst = RagaAICatalyst(\n",
    "    access_key=RAGA_ACCESS_KEY,\n",
    "    secret_key=RAGA_SECRET_KEY,\n",
    "    base_url=\"https://catalyst.raga.ai/api\"\n",
    ")\n",
    "\n",
    "# catalyst.project_use_cases()\n",
    "catalyst.list_projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracer started for project: BotTest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ragaai_catalyst.tracers.tracer.Tracer at 0x154629490>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # resources:\n",
    "# - https://docs.raga.ai/ragaai-catalyst-1/concepts/uploading-data/logging-traces\n",
    "# - https://colab.research.google.com/drive/1-Os-m_DTSnvpUhvqNoGnuyOOII7ni9YT?usp=sharing\n",
    "# - https://colab.research.google.com/drive/1XzhHQAAoNxrOUmBXyCj_N3Oe-Q_6HJd3?usp=sharing#scrollTo=3DGbYUlNE40A\n",
    "\n",
    "tracer = Tracer(\n",
    "    dataset_name=\"test_dataset\", # required to name dataset upon creation\n",
    "    project_name=\"BotTest\",\n",
    "    tracer_type=\"langchain\", #llama_index not available until beta release on 11/11\n",
    "    pipeline={\n",
    "        \"llm_model\": \"gpt-3.5-turbo\", # metadata\n",
    "        \"vector_store\": \"faiss\",\n",
    "        \"embed_model\": \"text-embedding-ada-002\",\n",
    "    },\n",
    "    #add your metadata as \"key\":\"value\" pairs\n",
    "    metadata={\"use-case\": \"YourUseCase\", \"stage\": \"testing-stage\"}\n",
    ")\n",
    "\n",
    "tracer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from opentelemetry.trace import SpanKind\n",
    "source_doc_path = \"inputs/data.pdf\"\n",
    "\n",
    "# Initialize necessary variables\n",
    "retriever = None\n",
    "loaded_doc = None\n",
    "def load_document(source_doc_path):\n",
    "\n",
    "    try:\n",
    "        loader = PyPDFLoader(source_doc_path)\n",
    "        pages = loader.load_and_split()\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        vectorstore = Chroma.from_documents(pages, embeddings)\n",
    "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "        print(\"Document loaded and processed.\")\n",
    "        return retriever\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the document: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_response(retriever, query):\n",
    "\n",
    "    try:\n",
    "        # llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "        template = \"\"\"\n",
    "            You are a helpful AI assistant. Answer based on the context provided.\n",
    "            context: {context}\n",
    "            input: {input}\n",
    "            answer:\n",
    "            \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "        retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "        response = retrieval_chain.invoke({\"input\": query})\n",
    "        print(response[\"answer\"])\n",
    "        return response[\"answer\"]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while generating the response: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_document(source_doc_path, loaded_doc, query):\n",
    "    try:\n",
    "        if loaded_doc != source_doc_path:\n",
    "            retriever = load_document(source_doc_path)\n",
    "            if retriever is None:\n",
    "                return \"Failed to load document.\"\n",
    "            loaded_doc = source_doc_path\n",
    "        else:\n",
    "            print(\"Using cached document retriever.\")\n",
    "        response = generate_response(retriever, query)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"An overall error occurred: {e}\")\n",
    "        return \"An error occurred during the document processing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The title of the paper is not explicitly provided in the given context. However, it is published in the \"Journal of the Brazilian Society of Mechanical Sciences and Engineering\" in 2023. If you need the specific title, please refer to the journal or article directly.\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the title of the paper.\"\n",
    "\n",
    "# Process the document and get the response\n",
    "response = process_document(source_doc_path, loaded_doc, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping tracer and initiating trace upload...\n",
      "Tracer provider shut down successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading traces: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading traces...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading traces: 1it [00:00,  2.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Trace upload initiated. Use get_upload_status() to check the status.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
