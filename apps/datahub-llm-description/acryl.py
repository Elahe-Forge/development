import time
from typing import Optional
from datahub.emitter.mce_builder import make_dataset_urn, make_tag_urn
from datahub.emitter.mcp import MetadataChangeProposalWrapper

# read-modify-write requires access to the DataHubGraph (RestEmitter is not enough)
from datahub.ingestion.graph.client import DatahubClientConfig, DataHubGraph

# Imports for metadata model classes
from datahub.metadata.schema_classes import (
    AuditStampClass,
    EditableSchemaFieldInfoClass,
    EditableSchemaMetadataClass,
    SchemaMetadataClass,
    EditableDatasetPropertiesClass,
    GlobalTagsClass,
    TagAssociationClass
)
from datahub.utilities.urns.field_paths import get_simple_field_path_from_v2_field_path


import logging
import os
from dotenv import load_dotenv


load_dotenv()
gms_endpoint = os.getenv('ACRYL_ENDPOINT')
token = os.getenv('ACRYL_TOKEN')

logger = logging.getLogger(__name__)
graph = DataHubGraph(config=DatahubClientConfig(server=gms_endpoint, token=token))  


def get_datasets():
    logger.info("Collecting datasets from Acryl")
    #return graph.list_all_entity_urns(entity_type='dataset', start=0, count=1)
    return [
        "urn:li:dataset:(urn:li:dataPlatform:snowflake,source.sharex_public.funding_rounds,PROD)",
        # "urn:li:dataset:(urn:li:dataPlatform:snowflake,edw.public.accounts,PROD)",
        # "urn:li:dataset:(urn:li:dataPlatform:snowflake,edw.public.closed_transactions,PROD)",
        # "urn:li:dataset:(urn:li:dataPlatform:snowflake,edw.public.pending_transactions,PROD)",
        # "urn:li:dataset:(urn:li:dataPlatform:snowflake,edw.public.ioi_inventory_v2,PROD)",
        # "urn:li:dataset:(urn:li:dataPlatform:snowflake,source.sharex_public.compliance_trade_reviews,PROD)",
        # "urn:li:dataset:(urn:li:dataPlatform:snowflake,source.ods_teleport_dbo.investmentbalancesnapshots,PROD)",
        # "urn:li:dataset:(urn:li:dataPlatform:snowflake,source.sharex_public.direct_trade_parties,PROD)",
        # "urn:li:dataset:(urn:li:dataPlatform:snowflake,source.sharex_public.signatures,PROD)",
        # "urn:li:dataset:(urn:li:dataPlatform:snowflake,edw.public.issuer_price_history,PROD)",
        # "urn:li:dataset:(urn:li:dataPlatform:snowflake,edw.public.events_markets,PROD)",
        # "urn:li:dataset:(urn:li:dataPlatform:snowflake,source.sharex_public.issuers,PROD)"
        ]

def get_glossary_term_urns():
    return graph.get_urns_by_filter(entity_types=["glossaryTerm"])

def get_glue_dataset_urns(platform='glue'):
    return graph.get_urns_by_filter(entity_types=["dataset"], platform=platform)

def extract_fields_in_metadata(metadata):
    return [ extract_name(field.fieldPath) for field in metadata.fields]

def get_table_definition_from_urn(urn, platform):
    logger.info(f"Collecting schema definition {urn} from Acryl")
    schema = graph.get_schema_metadata(entity_urn=urn)
    return {
        "platform": platform,
        "urn": urn,
        "full_name": schema.schemaName,
        "table_name": extract_name(schema.schemaName),
        "fields": extract_fields_in_metadata(schema)
    }

def get_tables(platform="glue"):
    datasets = get_glue_dataset_urns(platform)
    return [ get_table_definition_from_urn(dataset, platform) for dataset in datasets ]

def extract_name(field_path):
    return field_path.rsplit('.', 1)[-1]


def write_column_description(dataset_urn, column, description):
    documentation_to_add = f"{description} - This description was autogenerated by AI"
    tag_to_add = make_tag_urn("AI Generated")
    tag_association_to_add = TagAssociationClass(tag=tag_to_add)
    tags_aspect_to_set = GlobalTagsClass(tags=[tag_association_to_add])
    
    field_info_to_set = EditableSchemaFieldInfoClass(
        fieldPath=column, description=documentation_to_add, globalTags=tags_aspect_to_set
    )
    now = int(time.time() * 1000)  # milliseconds since epoch
    current_timestamp = AuditStampClass(time=now, actor="urn:li:corpuser:ingestion")

    current_editable_schema_metadata = graph.get_aspect(
        entity_urn=dataset_urn,
        aspect_type=SchemaMetadataClass, ## must use the generic MetadataClass, EditableSchemaMetadataClass skips fields never edited before
    )
    need_write = False
    
    if current_editable_schema_metadata:
        for fieldInfo in current_editable_schema_metadata.fields:
            if get_simple_field_path_from_v2_field_path(fieldInfo.fieldPath) == column:
                # we have some editable schema metadata for this field
                field_match = True
                if documentation_to_add != fieldInfo.description:
                    fieldInfo.description = documentation_to_add
                    need_write = True
                    
                if fieldInfo.globalTags:
                    if tag_to_add not in [x.tag for x in fieldInfo.globalTags.tags]:
                        # this tag is not present
                        fieldInfo.globalTags.tags.append(tag_association_to_add)
                        need_write = True
                else:
                    fieldInfo.globalTags = tags_aspect_to_set
                    need_write = True
    else:
    # create a brand new editable dataset properties aspect
        current_editable_schema_metadata = EditableSchemaMetadataClass(
            editableSchemaFieldInfo=[field_info_to_set],
            created=current_timestamp,
        )
        need_write = True

    if need_write:
        event: MetadataChangeProposalWrapper = MetadataChangeProposalWrapper(
            entityUrn=dataset_urn,
            aspect=current_editable_schema_metadata,
        )
        graph.emit(event)
        logger.info(f"Documentation added to dataset {dataset_urn} {column}")
        logger.info(f"Tag {tag_to_add} added to dataset {dataset_urn} {column}")

    else:
        logger.info("Documentation already exists and is identical, omitting write")
        logger.info(f"Tag {tag_to_add} already exists, omitting write")


def write_table_description(dataset_urn, description):
    now = int(time.time() * 1000)  # milliseconds since epoch
    current_timestamp = AuditStampClass(time=now, actor="urn:li:corpuser:ingestion")
    
    documentation_to_add = f"{description} - This description was autogenerated by AI"
    
    current_editable_properties = graph.get_aspect(
        entity_urn=dataset_urn, aspect_type=EditableDatasetPropertiesClass
    )

    need_write = False
    if current_editable_properties:
        if documentation_to_add != current_editable_properties.description:
            current_editable_properties.description = documentation_to_add
            need_write = True
    else:
        # create a brand new editable dataset properties aspect
        current_editable_properties = EditableDatasetPropertiesClass(
            created=current_timestamp, description=documentation_to_add
        )
        need_write = True

    if need_write:
        event: MetadataChangeProposalWrapper = MetadataChangeProposalWrapper(
            entityUrn=dataset_urn,
            aspect=current_editable_properties,
        )
        graph.emit(event)
        logger.info(f"Documentation added to dataset {dataset_urn}")

    else:
        logger.info("Documentation already exists and is identical, omitting write")
        

def add_tag_to_table(dataset_urn, tag):
    current_tags: Optional[GlobalTagsClass] = graph.get_aspect(
        entity_urn=dataset_urn,
        aspect_type=GlobalTagsClass,
    )

    tag_to_add = make_tag_urn(tag)
    tag_association_to_add = TagAssociationClass(tag=tag_to_add)

    need_write = False
    if current_tags:
        if tag_to_add not in [x.tag for x in current_tags.tags]:
            # tags exist, but this tag is not present in the current tags
            current_tags.tags.append(TagAssociationClass(tag_to_add))
            need_write = True
    else:
        # create a brand new tags aspect
        current_tags = GlobalTagsClass(tags=[tag_association_to_add])
        need_write = True

    if need_write:
        event: MetadataChangeProposalWrapper = MetadataChangeProposalWrapper(
            entityUrn=dataset_urn,
            aspect=current_tags,
        )
        graph.emit(event)
        logger.info(f"Tag {tag_to_add} added to dataset {dataset_urn}")

    else:
        logger.info(f"Tag {tag_to_add} already exists, omitting write")

# TODO implement glossary terms
# unfortunately these terms needs to be pulled from acryl and matched properly with get_glossary_term_urns()
# Glossary terms use UUIDs and not human readable strings like tags        
def add_glossary_term_to_table(dataset_urn, glossary_term):
    logger.info(f"Skipped adding Term {glossary_term} to {dataset_urn}, feature not implemented")